active_learning:
  default_batch_size: 10
  fine_tuned_confidence_threshold: 0.7
  high_confidence_threshold: 0.9
  selection_strategy: uncertainty
  uncertainty_threshold: 0.7
  use_fine_tuned_if_available: true
dataset:
  max_sequence_length: 512
  min_document_length: 20
  min_entities_per_document: 1
  require_validation: true
feedback_loop:
  auto_training_threshold: 100
  check_interval_seconds: 3600
  enabled: true
  primary_evaluation_metric: f1_score
labels:
  label_list:
  - O
  - B-codice_civile
  - I-codice_civile
  - B-codice_penale
  - I-codice_penale
  - B-codice_procedura_civile
  - I-codice_procedura_civile
  - B-codice_procedura_penale
  - I-codice_procedura_penale
  - B-codice_beni_culturali
  - I-codice_beni_culturali
  - B-decreto_legislativo
  - I-decreto_legislativo
  - B-decreto_legge
  - I-decreto_legge
  - B-decreto_presidente_repubblica
  - I-decreto_presidente_repubblica
  - B-decreto_ministeriale
  - I-decreto_ministeriale
  - B-dpcm
  - I-dpcm
  - B-legge
  - I-legge
  - B-legge_costituzionale
  - I-legge_costituzionale
  - B-costituzione
  - I-costituzione
  - B-testo_unico
  - I-testo_unico
  - B-regolamento_ue
  - I-regolamento_ue
  - B-direttiva_ue
  - I-direttiva_ue
  - B-trattato_ue
  - I-trattato_ue
  - B-convenzione_europea_diritti
  - I-convenzione_europea_diritti
  - B-codice
  - I-codice
logging:
  backup_count: 5
  enabled: true
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  level: INFO
  log_file_path: logs/active_learning.log
  log_to_console: true
  log_to_file: true
  max_bytes: 10485760
minio:
  access_key: minioadmin
  bucket: legal-ner-datasets
  endpoint: localhost:9000
  secret_key: minioadmin
  secure: false
monitoring:
  alert_if_eval_loss_above: 1.0
  alert_if_f1_below: 0.8
  track_metrics:
  - precision
  - recall
  - f1
  - loss
paths:
  models_base_dir: models/active_learning
  temp_datasets_dir: temp/datasets
  training_logs_dir: logs/training
training:
  base_model: DeepMount00/Italian_NER_XXL_v2
  eval_split: 0.2
  eval_strategy: epoch
  learning_rate: 2.0e-05
  load_best_model_at_end: true
  metric_for_best_model: eval_loss
  min_training_samples: 50
  num_train_epochs: 20
  per_device_eval_batch_size: 8
  per_device_train_batch_size: 8
  save_strategy: epoch
  save_total_limit: 2
  warmup_steps: 100
  weight_decay: 0.01
ui:
  annotation_timeout: 30
  entities_per_page: 20
  port: 5000
versioning:
  keep_best_n_models: 3
  save_metadata:
  - training_samples
  - eval_loss
  - dataset_version
  - base_model
  - training_duration
  timestamp_format: '%Y%m%d_%H%M%S'
  version_prefix: active_learning
