# Analisi Flusso End-to-End: Legal-NER Active Learning System

**Data**: 2025-09-30
**Obiettivo**: Identificare fallacie logiche e architetturali che impediscono al sistema di essere state-of-the-art

---

## 1. FLUSSO ATTUALE

### Fase 1: Creazione Task
1. Utente carica documento (testo o file)
2. Sistema crea `Document` in DB
3. Se richiesto, pre-processing con `/process` â†’ estrae entitÃ  con specialized pipeline
4. Sistema crea `AnnotationTask`
5. Utente accede a pagina di annotazione

### Fase 2: Annotazione
1. Utente visualizza entitÃ  estratte
2. Utente puÃ²:
   - Confermare/correggere entitÃ 
   - Aggiungere nuove entitÃ 
   - Eliminare entitÃ  sbagliate
   - Re-applicare il modello

### Fase 3: Feedback & Learning
1. Feedback salvato in DB
2. Active Learning seleziona sample per annotazione
3. Training triggato manualmente
4. Fine-tuning del modello con dataset annotato

### Fase 4: Export
1. EntitÃ  convertite in formato VisuaLex
2. Export per scraping

---

## 2. CRITICITÃ€ ARCHITETTURALI IDENTIFICATE

### ğŸ”´ CRITICA 1: Mancanza di ciclo di feedback automatico
**Problema**: Il sistema non chiude automaticamente il ciclo di active learning
- Non c'Ã¨ trigger automatico per training quando si raggiunge una soglia di annotazioni
- Non c'Ã¨ valutazione automatica delle performance dopo training
- Non c'Ã¨ re-deployment automatico del modello migliorato

**Impatto**: Il modello non migliora autonomamente nel tempo
**Soluzione**: Implementare feedback loop automatico con:
- Soglie configurabili (es. ogni 100 annotazioni â†’ training)
- Valutazione automatica su golden dataset
- A/B testing tra modello vecchio e nuovo
- Auto-deployment se accuracy migliora

---

### ğŸ”´ CRITICA 2: Nessuna strategia di uncertainty sampling
**Problema**: Active learning seleziona sample casuali o con criterio sconosciuto
- Non c'Ã¨ implementazione di uncertainty-based selection
- Non ci sono metriche di incertezza calcolate sulle predizioni
- Manca diversitÃ  nel campionamento (no cluster-based selection)

**Impatto**: Annotazioni sprecate su sample non informativi
**Soluzione**: Implementare:
- Entropy-based uncertainty per entitÃ 
- Margin sampling (differenza tra top-2 classi)
- Query-by-committee con ensemble
- Diversity sampling basato su embeddings

---

### ğŸ”´ CRITICA 3: Specialized Pipeline non aggiornabile
**Problema**: La specialized pipeline usa modelli fissi
- Stage 1 (EntityDetector) usa sempre `Italian_NER_XXL_v2` base
- Non integra i modelli fine-tunati dal active learning
- Rule-based classifier ha prioritÃ  su modello semantico

**Impatto**: Il sistema non migliora con le annotazioni
**Soluzione**:
- Sostituire modello base con modello fine-tunato quando disponibile
- Hot-swap dei modelli senza restart
- Versioning dei modelli con rollback

---

### ğŸŸ¡ CRITICA 4: Mancanza di inter-annotator agreement
**Problema**: Sistema single-annotator senza validazione
- Nessun meccanismo di doppia annotazione
- Nessuna metrica di quality control (Cohen's Kappa, Fleiss' Kappa)
- Non c'Ã¨ risoluzione di conflitti tra annotatori

**Impatto**: Dataset contaminato da errori/bias di singolo annotatore
**Soluzione**:
- Multi-annotator workflow
- Calcolo agreement metrics
- Adjudication interface per risolvere conflitti

---

### ğŸŸ¡ CRITICA 5: VisuaLex mapping incompleto
**Problema**: Conversione NER â†’ VisuaLex perde informazioni
- Article extraction da regex puÃ² fallire
- Non valida se act_number/date sono coerenti
- Nessun fallback per entitÃ  ambigue

**Impatto**: Perdita di entitÃ  valide, scraper riceve dati incompleti
**Soluzione**:
- LLM-based extraction per componenti mancanti
- Validazione semantica act_type + act_number + date
- Confidence threshold per export

---

### ğŸŸ¡ CRITICA 6: Nessuna gestione della distribuzione dei dati
**Problema**: Non c'Ã¨ class balancing o data augmentation
- Dataset puÃ² essere sbilanciato (troppe leggi, pochi decreti)
- Nessuna tecnica di oversampling/undersampling
- Non si tracciano metriche per-class

**Impatto**: Modello biased verso classi maggioritarie
**Soluzione**:
- Class balancing durante training
- SMOTE o data augmentation per classi rare
- Per-class metrics (precision/recall/F1)

---

### ğŸŸ¡ CRITICA 7: Mancanza di continual learning
**Problema**: Training da zero ogni volta
- Non usa tecniche di continual learning
- Rischio di catastrophic forgetting
- Non preserva conoscenza su sample vecchi

**Impatto**: Performance degrada su sample annotati in passato
**Soluzione**:
- Elastic Weight Consolidation (EWC)
- Replay buffer con sample vecchi
- Progressive neural networks

---

### ğŸŸ¢ CRITICA 8: Nessun human-in-the-loop per casi critici
**Problema**: Sistema non escalata casi difficili
- Non identifica predizioni low-confidence
- Non chiede validazione umana su entitÃ  critiche
- Non suggerisce alternative

**Impatto**: Errori silenti su casi edge
**Soluzione**:
- Confidence threshold per human review
- Suggerimenti basati su similarity con golden dataset
- Active prompting per casi ambigui

---

### ğŸŸ¢ CRITICA 9: Logging insufficiente per ML Ops
**Problema**: Logging orientato a debug, non a ML metrics
- Non traccia model drift
- Non salva feature distributions
- Non monitora latency/throughput

**Impatto**: Impossibile diagnosticare problemi in produzione
**Soluzione**:
- MLflow o Weights&Biases integration
- Feature drift detection (Kolmogorov-Smirnov test)
- Performance monitoring dashboards

---

### ğŸŸ¢ CRITICA 10: Export non bidirezionale
**Problema**: VisuaLex export Ã¨ unidirezionale
- Non re-importa risultati da scraper
- Non valida se scraping ha avuto successo
- Nessun feedback loop da VisuaLex al NER

**Impatto**: Errori di estrazione non vengono corretti
**Soluzione**:
- Import risultati scraping
- Validazione NER vs scraper output
- Correzione automatica basata su scraping

---

## 3. PRIORITÃ€ DI IMPLEMENTAZIONE

### Priority 1 (Blockers per State-of-the-Art)
1. **Uncertainty Sampling** â†’ Senza questo, active learning non funziona
2. **Modello Aggiornabile** â†’ Pipeline deve usare modelli fine-tunati
3. **Feedback Loop Automatico** â†’ Sistema deve migliorare autonomamente

### Priority 2 (Quality Improvements)
4. **Inter-Annotator Agreement** â†’ QualitÃ  dataset
5. **Class Balancing** â†’ Performance su classi rare
6. **Continual Learning** â†’ No catastrophic forgetting

### Priority 3 (Production Readiness)
7. **MLOps Integration** â†’ Monitoring e debugging
8. **Human-in-the-Loop** â†’ Validazione casi critici
9. **VisuaLex Validation** â†’ Export piÃ¹ robusto
10. **Bidirectional Export** â†’ Feedback da scraper

---

## 4. ARCHITETTURA PROPOSTA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INTERFACE (Flask)                   â”‚
â”‚  [Upload] [Annotate] [Review] [Train] [Deploy] [Monitor]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FASTAPI BACKEND (Orchestrator)                  â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   ACTIVE LEARNING ENGINE (Priority 1)                â”‚   â”‚
â”‚  â”‚   - Uncertainty Sampler                              â”‚   â”‚
â”‚  â”‚   - Diversity Sampler                                â”‚   â”‚
â”‚  â”‚   - Query-by-Committee                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   MODEL MANAGER (Priority 1)                         â”‚   â”‚
â”‚  â”‚   - Model Versioning                                 â”‚   â”‚
â”‚  â”‚   - Hot-Swap Pipeline                                â”‚   â”‚
â”‚  â”‚   - A/B Testing                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   SPECIALIZED PIPELINE (Updated)                     â”‚   â”‚
â”‚  â”‚   Stage 1: EntityDetector â†’ Uses LATEST fine-tuned  â”‚   â”‚
â”‚  â”‚   Stage 2: LegalClassifier â†’ Hybrid (semantic+rule) â”‚   â”‚
â”‚  â”‚   Stage 3-5: Parser/Resolver/Builder                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   TRAINING ORCHESTRATOR (Priority 1)                 â”‚   â”‚
â”‚  â”‚   - Threshold Monitor (auto-trigger training)        â”‚   â”‚
â”‚  â”‚   - Class Balancer                                   â”‚   â”‚
â”‚  â”‚   - Continual Learning (EWC)                         â”‚   â”‚
â”‚  â”‚   - Model Evaluator                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   ANNOTATION QUALITY CONTROL (Priority 2)            â”‚   â”‚
â”‚  â”‚   - Inter-Annotator Agreement                        â”‚   â”‚
â”‚  â”‚   - Conflict Resolution                              â”‚   â”‚
â”‚  â”‚   - Outlier Detection                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STORAGE LAYER                             â”‚
â”‚  [PostgreSQL] [MinIO] [Redis Cache] [MLflow]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               EXTERNAL INTEGRATIONS                          â”‚
â”‚  [VisuaLex Scraper] â† Bidirectional â†’ [Feedback Import]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. METRICHE DA TRACCIARE

### Performance Metrics
- Per-class Precision/Recall/F1
- Overall Accuracy
- Cohen's Kappa (inter-annotator)
- Model Confidence Distribution

### Active Learning Metrics
- Uncertainty Score per Sample
- Diversity Score
- Annotation Efficiency (Î” Performance / Annotation)
- Oracle Query Rate

### Production Metrics
- Inference Latency (p50, p95, p99)
- Throughput (requests/sec)
- Model Drift (KS statistic)
- Error Rate by Entity Type

---

## 6. CONCLUSIONI

Il sistema attuale Ã¨ **funzionale ma non state-of-the-art** perchÃ©:

1. âŒ **Active Learning Ã¨ passivo**: Non seleziona sample informativi
2. âŒ **Pipeline non migliora**: Modelli fissi, non aggiornati
3. âŒ **Nessun controllo qualitÃ **: Single-annotator, no validation
4. âŒ **Training manuale**: Nessun ciclo automatico
5. âš ï¸ **Export limitato**: Unidirezionale, nessuna validazione

Per diventare **state-of-the-art**, servono:
- Uncertainty sampling intelligente
- Hot-swap modelli fine-tunati
- Feedback loop automatico
- Quality control annotations
- MLOps integration completa

**Stima effort**:
- Priority 1 â†’ 2-3 settimane
- Priority 2 â†’ 1-2 settimane
- Priority 3 â†’ 1-2 settimane

**Total**: ~6 settimane per sistema production-ready e state-of-the-art